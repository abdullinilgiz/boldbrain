{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_betas_path = '../data/processed_data/subj01/nsd_train_fmriavg_nsdgeneral_sub1.npy'\n",
    "train_caps_embed_path = '../data/caps_embeds/train_caps_embeds_sub1.npy'\n",
    "train_caps_embed_neg_path = '../data/caps_embeds/train_caps_embeds_negative_sub1.npy'\n",
    "\n",
    "# train_betas = np.load(train_betas_path)\n",
    "# train_caps_embed = np.load(train_caps_embed_path)\n",
    "# train_caps_embed_neg = np.load(train_caps_embed_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_betas_path = '../data/caps_embeds/test_betas_split_sub1.npy'\n",
    "test_caps_embed_path = '../data/caps_embeds/test_caps_embeds_split_sub1.npy'\n",
    "test_caps_embed_neg_path = '../data/caps_embeds/test_caps_embeds_negative_split_sub1.npy'\n",
    "\n",
    "# test_betas = np.load(test_betas_path)\n",
    "# test_caps_embed = np.load(test_caps_embed_path)\n",
    "# test_caps_embed_neg = np.load(test_caps_embed_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_betas_path = '../data/caps_embeds/val_betas_split_sub1.npy'\n",
    "val_caps_embed_path = '../data/caps_embeds/val_caps_embeds_split_sub1.npy'\n",
    "val_caps_embed_neg_path = '../data/caps_embeds/val_caps_embeds_split_negative_sub1.npy'\n",
    "\n",
    "# val_betas = np.load(val_betas_path)\n",
    "# val_caps_embed = np.load(val_caps_embed_path)\n",
    "# val_caps_embed_neg = np.load(val_caps_embed_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta      torch.Size([64, 15724])\n",
      "embed     torch.Size([64, 1280])\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, betas_path, embeds_path):\n",
    "        self.betas = torch.from_numpy(np.load(betas_path)).float().cuda()\n",
    "        self.embeds = torch.from_numpy(\n",
    "                np.squeeze(np.load(embeds_path))\n",
    "            ).float().cuda()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.betas)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.betas[index], self.embeds[index]\n",
    "\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_loader)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = CustomDataset(train_betas_path,\n",
    "                              train_caps_embed_path,)\n",
    "train_data_loader = CustomDataLoader(train_dataset, batch_size)\n",
    "\n",
    "test_dataset = CustomDataset(test_betas_path,\n",
    "                             test_caps_embed_path,)\n",
    "test_data_loader = CustomDataLoader(test_dataset, batch_size)\n",
    "\n",
    "val_dataset = CustomDataset(val_betas_path,\n",
    "                            val_caps_embed_path,)\n",
    "val_data_loader = CustomDataLoader(val_dataset, batch_size)\n",
    "\n",
    "for beta, embed in train_data_loader:\n",
    "    print(f\"beta      {beta.shape}\")\n",
    "    print(f\"embed     {embed.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 15724\n",
      "output_dim: 1280\n"
     ]
    }
   ],
   "source": [
    "input_dim = 15724\n",
    "print('input_dim:', input_dim)\n",
    "ouput_dim = 1280\n",
    "print('output_dim:', ouput_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.linear_regression = nn.Linear(in_features=input_channels,\n",
    "                               out_features=output_channels)\n",
    "        self.layer1 = 2**10 * 8\n",
    "        self.layer2 = 2**10 * 2\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=input_channels, \n",
    "                      out_features=self.layer1),\n",
    "            nn.LeakyReLU(0.05, inplace=True),    \n",
    "            nn.Linear(in_features=self.layer1, \n",
    "                      out_features=self.layer2),\n",
    "            nn.LeakyReLU(0.05, inplace=True),    \n",
    "            nn.Linear(in_features=self.layer2, \n",
    "                      out_features=output_channels),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "model_embed = RegressionModel(input_dim, ouput_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineSimilarityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        cosine_sim = F.cosine_similarity(y_true, y_pred, dim=1)\n",
    "        loss = 1 - cosine_sim.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilgiz/dev/boldbrain/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "cos_loss = CosineSimilarityLoss()\n",
    "mse_loss = nn.MSELoss(reduction='mean')\n",
    "optim_embed = torch.optim.Adam(\n",
    "    params=model_embed.parameters(), lr=0.0001, weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'mlp_one_model' #+ datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "writer = SummaryWriter(os.path.join('runs', run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 2.7120538651943207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:13<21:47, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 2.3417610228061676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:26<21:23, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 2.032508000731468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:39<21:06, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.812092900276184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:52<20:51, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.6159464567899704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:05<20:36, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.4572540074586868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:18<20:22, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.338688462972641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:31<20:12, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.2492763549089432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:44<19:59, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.1621614694595337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:57<19:44, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.109212189912796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:10<19:31, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.0597576647996902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [02:23<19:19, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 1.018299974501133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [02:36<19:09, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.9905326217412949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [02:49<18:56, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.9645259454846382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [03:02<18:42, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.9402236863970757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [03:15<18:29, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.9317614734172821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [03:28<18:15, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.90281593054533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [03:41<18:00, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8877482712268829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [03:54<17:48, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8816548511385918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [04:19<16:45, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8652753531932831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [04:32<16:42, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8562572300434113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [04:45<16:37, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8551634326577187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [04:58<16:29, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8513344973325729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [05:11<16:21, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8423099964857101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [05:24<16:12, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.839881032705307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [05:37<16:01, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.835456408560276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [05:50<15:50, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8287530690431595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [06:03<15:37, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8286100998520851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [06:16<15:25, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8251029998064041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [06:29<15:12, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8189946115016937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [06:54<14:15, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.816073901951313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [07:07<14:12, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.812539592385292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [07:20<14:06, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.807425431907177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [07:33<13:57, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.8071509301662445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [07:46<13:48, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.7994620427489281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [08:33<12:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.7966928258538246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [08:47<12:07, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with loss: 0.7964910864830017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:07<00:00, 12.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "iter_index = 0\n",
    "min_test_loss = 1e15\n",
    "best_model_path = f'../models/{run_name}.pth'\n",
    "test_iter_index = 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model_embed.train()\n",
    "    for betas, embeds in train_data_loader:\n",
    "        iter_index += 1\n",
    "        pred_embeds = model_embed(betas)\n",
    "\n",
    "        loss_embed = mse_loss(pred_embeds, embeds)\n",
    "        optim_embed.zero_grad()\n",
    "        loss_embed.backward()\n",
    "        optim_embed.step()\n",
    "\n",
    "        writer.add_scalars('train/losses', {\n",
    "            'embed': loss_embed.item(),\n",
    "        }, iter_index)\n",
    "    \n",
    "    test_loss = 0\n",
    "    model_embed.eval()\n",
    "    with torch.inference_mode():\n",
    "        n_batches = 0\n",
    "        for betas, embeds in val_data_loader:\n",
    "            test_iter_index += 1\n",
    "            pred_embeds = model_embed(betas)\n",
    "\n",
    "            loss_embed = mse_loss(pred_embeds, embeds)\n",
    "\n",
    "            cos_embed = cos_loss(pred_embeds, embeds)\n",
    "\n",
    "            writer.add_scalars('val/losses', {\n",
    "                'embed': loss_embed.item(),\n",
    "            }, test_iter_index)\n",
    "\n",
    "            writer.add_scalars('val/cos_sim', {\n",
    "                'cos_embed': cos_embed.item(),\n",
    "            }, test_iter_index)\n",
    "\n",
    "            n_batches += 1\n",
    "            test_loss += loss_embed.item()\n",
    "\n",
    "    test_loss /= n_batches\n",
    "    if test_loss < min_test_loss:\n",
    "        min_test_loss = test_loss\n",
    "        print(f'Model saved with loss: {test_loss}')\n",
    "        torch.save({\n",
    "            'model_embed_state_dict': model_embed.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'min_test_loss': min_test_loss,\n",
    "        }, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    n_batches = 0\n",
    "    for betas, embeds in test_data_loader:\n",
    "        test_iter_index += 1\n",
    "        pred_embeds = model_embed(betas)\n",
    "\n",
    "        loss_embed = mse_loss(pred_embeds, embeds)\n",
    "\n",
    "        cos_embed = cos_loss(pred_embeds, embeds)\n",
    "\n",
    "        writer.add_scalars('test/losses', {\n",
    "            'embed': loss_embed.item(),\n",
    "        }, test_iter_index)\n",
    "\n",
    "        writer.add_scalars('test/cos_sim', {\n",
    "            'cos_embed': cos_embed.item(),\n",
    "        }, test_iter_index)\n",
    "\n",
    "        n_batches += 1\n",
    "        test_loss += loss_embed.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
